import os
import json
import glob
import logging
import re
import html
from typing import List, Dict, Any, Optional, Match

from fastapi import FastAPI
from fastapi.responses import JSONResponse

# Added: urllib for Telegram Bot API publishing
from urllib import request as urlrequest
from urllib.error import HTTPError, URLError

from .config import settings
import time

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s [%(name)s] %(message)s")
logger = logging.getLogger("aggregator.main")

app = FastAPI(title="MediaGenerator Aggregator", version="0.1.0")


# -------------------- IO helpers --------------------

def _write_summary_file(path: str, content: str, *, encoding: str) -> bool:
    try:
        with open(path, "w", encoding=encoding) as f:
            f.write(content)
        logger.info(f"Summary written: path={path} len={len(content)} encoding={encoding}")
        return True
    except Exception:
        logger.exception("Failed to write summary to %s", path)
        return False


def _remove_approved(items: List[Dict[str, Any]]) -> List[str]:
    removed: List[str] = []
    for it in items:
        try:
            os.remove(it["path"])  # type: ignore[arg-type]
            removed.append(os.path.basename(it["path"]))
        except Exception:
            logger.exception("Failed to remove %s", it["path"])  # type: ignore[index]
    logger.info(f"Approved removed: count={len(removed)}")
    return removed


# -------------------- Data loading --------------------

def _read_approved(limit: Optional[int] = None) -> List[Dict[str, Any]]:
    pattern = os.path.join(settings.APPROVED_DIR, "*.json")
    files = sorted(glob.glob(pattern))
    if limit:
        files = files[:limit]
    items: List[Dict[str, Any]] = []
    for p in files:
        try:
            with open(p, "r", encoding="utf-8") as f:
                payload = json.load(f)
            items.append({"path": p, "payload": payload})
        except Exception:
            logger.exception("Failed to read %s", p)
    return items


# -------------------- Prompt & LLM --------------------

def _compose_prompt(items: List[Dict[str, Any]], lang: str) -> str:
    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –º–æ–¥–µ–ª–∏: —Å—Ç—Ä–æ–≥–∏–π Markdown-—Ñ–æ—Ä–º–∞—Ç –¥–ª—è Telegram
    if lang == "ru":
        lines: List[str] = [
            "–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤. –°—Ñ–æ—Ä–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Telegram.",
            "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –≤—ã–≤–µ–¥–∏ –†–û–í–ù–û —Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏:",
            "1) –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞–∫ –∂–∏—Ä–Ω–∞—è Markdown-—Å—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç: **[–ó–∞–≥–æ–ª–æ–≤–æ–∫](URL)**. –ï—Å–ª–∏ URL –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –∂–∏—Ä–Ω—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ–∑ —Å—Å—ã–ª–∫–∏.",
            "2) –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ –∏ –æ—Ç—Å—ã–ª–∫–∞ –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É –ë–ï–ó @username: –∏—Å–ø–æ–ª—å–∑—É–π –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ‚Äòüì∞ –ö–∞–∫ —Å–æ–æ–±—â–∞–µ—Ç <–ò–º—è–ö–∞–Ω–∞–ª–∞>, ‚Ä¶‚Äô, ‚Äòüß† –ü–æ –¥–∞–Ω–Ω—ã–º <–ò–º—è–ö–∞–Ω–∞–ª–∞>, ‚Ä¶‚Äô, ‚Äòüì£ –í –∫–∞–Ω–∞–ª–µ <–ò–º—è–ö–∞–Ω–∞–ª–∞> –æ—Ç–º–µ—á–∞—é—Ç, ‚Ä¶‚Äô). –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–Ω—É –∏ —Ç—É –∂–µ —Ñ—Ä–∞–∑—É.",
            "3) –¢—Ä–µ—Ç—å—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).",
            "–ú–µ–∂–¥—É –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ ‚Äî –æ–¥–Ω–∞ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏, –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤, HTML –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è. –í—ã–≤–æ–¥–∏ —Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Markdown.",
        ]
    else:
        lines = [
            f"You are a digest editor. Produce a concise digest in {lang} strictly in Telegram-ready Markdown.",
            "For each item output EXACTLY three lines:",
            "1) First line ‚Äî short title as a bold Markdown link to the original post: **[Title](URL)**. If URL is missing ‚Äî just a bold short title without link.",
            "2) Second line ‚Äî exactly one relevant emoji at the start and attribution to the source WITHOUT @username; vary the phrasing across items.",
            "3) Third line ‚Äî brief summary (2‚Äì4 sentences).",
            "Separate items with a single empty line. No lists, section headers, HTML or extra explanations. Output only the Markdown result.",
        ]
    lines.append("–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º (title, url, text):" if lang == "ru" else "Input items (title, url, text):")
    for it in items:
        p = it["payload"]
        # –ë–µ—Ä—ë–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏—è, –∞ –Ω–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
        title = p.get("title") or p.get("channel_title") or p.get("channel_name") or ("–ö–∞–Ω–∞–ª" if lang == "ru" else "Channel")
        url = _build_message_url(p)
        text = p.get("text") or (p.get("media") or {}).get("caption") or ""
        if text and len(text) > settings.TEXT_TRUNCATE_LIMIT:
            text = text[: settings.TEXT_TRUNCATE_LIMIT] + "‚Ä¶"
        lines.append(f"- title: {title}")
        lines.append(f"  url: {url}")
        lines.append("  text: |")
        for ln in (text or "").splitlines():
            lines.append(f"    {ln}")
        lines.append("")
    lines.append("–í—ã–≤–µ–¥–∏ —Ç–æ–ª—å–∫–æ –∏—Ç–æ–≥–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ Markdown –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—Ä–∞–≤–∏–ª–∞–º." if lang == "ru" else "Output only the final Markdown digest.")
    return "\n".join(lines)


def _markdown_to_html_safe(text: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ Markdown-—Å—Å—ã–ª–∫–∏ [text](url) –∏ –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç **text** –≤ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π HTML.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ http/https —Å—Å—ã–ª–∫–∏. –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è–µ–º —Å—Å—ã–ª–∫–∏ –∏ –∂–∏—Ä–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞–º–∏,
    –∑–∞—Ç–µ–º —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Ü–µ–ª–∏–∫–æ–º –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∫–∞–∫ HTML-—Ç–µ–≥–∏.
    """
    placeholders: List[str] = []
    bold_placeholders: List[str] = []

    # 1) –°—Å—ã–ª–∫–∏ -> –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
    def repl_link(m: Match) -> str:
        title = m.group(1)
        url = m.group(2)
        anchor = '<a href="{href}">{title}</a>'.format(href=html.escape(url, quote=True), title=html.escape(title))
        placeholders.append(anchor)
        return f"__LINK_PLACEHOLDER_{len(placeholders)-1}__"

    pattern_link = re.compile(r"\[([^\]]+)\]\((https?://[^\s)]+)\)")
    tmp = pattern_link.sub(repl_link, text)

    # 2) –ñ–∏—Ä–Ω—ã–π -> –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
    def repl_bold(m: Match) -> str:
        inner = m.group(1)
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∂–∏—Ä–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∫–∞–∫ –µ—Å—Ç—å
        inner_esc = html.escape(inner)
        bold_placeholders.append(f"<b>{inner_esc}</b>")
        return f"__BOLD_PLACEHOLDER_{len(bold_placeholders)-1}__"

    pattern_bold = re.compile(r"\*\*([^*]+)\*\*")
    tmp2 = pattern_bold.sub(repl_bold, tmp)

    # 3) –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
    escaped = html.escape(tmp2)

    # 4) –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∂–∏—Ä–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    for i, b in enumerate(bold_placeholders):
        escaped = escaped.replace(f"__BOLD_PLACEHOLDER_{i}__", b)

    # 5) –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —è–∫–æ—Ä—è-—Å—Å—ã–ª–∫–∏
    for i, a in enumerate(placeholders):
        escaped = escaped.replace(f"__LINK_PLACEHOLDER_{i}__", a)

    return escaped


# -------------------- LLM call --------------------

def _use_gemini(prompt: str) -> str:
    try:
        import google.generativeai as genai  # type: ignore
        genai.configure(api_key=settings.GEMINI_API_KEY)
        model_name = settings.GEMINI_MODEL_NAME
        start = time.perf_counter()
        logger.info(f"Gemini request: model={model_name} prompt_len={len(prompt)}")
        model = genai.GenerativeModel(model_name)
        resp = model.generate_content(prompt)
        duration_ms = int((time.perf_counter() - start) * 1000)
        text = (resp.text or "").strip()
        logger.info(f"Gemini response: ok={bool(text)} text_len={len(text)} duration_ms={duration_ms}")
        return text
    except Exception as e:
        logger.exception("Gemini call failed: %s", e)
        return ""


def _md_to_plain(text: str) -> str:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Markdown-—Å—Å—ã–ª–∫–∏ [–¢–µ–∫—Å—Ç](URL) ‚Üí '–¢–µ–∫—Å—Ç - URL'
    try:
        return re.sub(r"\[([^\]]+)\]\(([^)]+)\)", r"\1 - \2", text)
    except Exception:
        return text

# -------------------- Telegram publishing --------------------

def _publish_telegram(markdown_text: str) -> bool:
    if not (settings.BOT_TOKEN and settings.TARGET_CHANNEL_ID):
        logger.warning("Telegram publishing skipped: BOT_TOKEN or TARGET_CHANNEL_ID is not set")
        return False
    try:
        api_url = f"https://api.telegram.org/bot{settings.BOT_TOKEN}/sendMessage"
        body = {
            "chat_id": settings.TARGET_CHANNEL_ID,
            "text": markdown_text,
            "disable_web_page_preview": settings.TELEGRAM_DISABLE_WEB_PREVIEW,
        }
        # parse_mode –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –∑–∞–¥–∞–Ω
        if settings.TELEGRAM_PARSE_MODE:
            body["parse_mode"] = settings.TELEGRAM_PARSE_MODE
        logger.info(
            f"Publishing to Telegram: chat_id={settings.TARGET_CHANNEL_ID} text_len={len(markdown_text)} parse_mode={settings.TELEGRAM_PARSE_MODE}"
        )
        req = urlrequest.Request(
            api_url,
            data=json.dumps(body, ensure_ascii=False).encode("utf-8"),
            headers={"Content-Type": "application/json"},
        )
        with urlrequest.urlopen(req, timeout=settings.TELEGRAM_TIMEOUT_SEC) as resp:
            status = resp.status
            raw = ""
            try:
                raw = resp.read().decode("utf-8", errors="ignore")
            except Exception:
                raw = ""
            if status != 200:
                logger.warning(f"Bot API non-200 response: {status} body={raw[:200]}")
                return False
            # –ü–∞—Ä—Å–∏–º JSON –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–µ ok
            try:
                j = json.loads(raw)
            except Exception:
                j = None
            if isinstance(j, dict):
                if not j.get("ok", False):
                    desc = j.get("description", "") or ""
                    logger.error(f"Bot API returned ok=false: {desc}")
                    # –§–æ–ª–±—ç–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π
                    if "can't parse entities" in desc.lower():
                        try:
                            plain = _md_to_plain(markdown_text)
                            body2 = {
                                "chat_id": settings.TARGET_CHANNEL_ID,
                                "text": plain,
                                "disable_web_page_preview": settings.TELEGRAM_DISABLE_WEB_PREVIEW,
                            }
                            req2 = urlrequest.Request(
                                api_url,
                                data=json.dumps(body2, ensure_ascii=False).encode("utf-8"),
                                headers={"Content-Type": "application/json"},
                            )
                            with urlrequest.urlopen(req2, timeout=settings.TELEGRAM_TIMEOUT_SEC) as resp2:
                                raw2 = ""
                                try:
                                    raw2 = resp2.read().decode("utf-8", errors="ignore")
                                except Exception:
                                    raw2 = ""
                                try:
                                    j2 = json.loads(raw2)
                                except Exception:
                                    j2 = None
                                ok2 = bool(j2 and j2.get("ok", False))
                                if not ok2:
                                    logger.warning(f"Retry Bot API ok=false: {raw2[:200]}")
                                return ok2
                        except Exception as e2:
                            logger.exception(f"Retry without parse_mode failed: {e2}")
                    return False
            else:
                # –ï—Å–ª–∏ –Ω–µ JSON ‚Äî —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –æ—à–∏–±–∫–æ–π
                logger.warning(f"Bot API returned non-JSON body: {raw[:200]}")
                return False
            # –£—Å–ø–µ—Ö
            return True
    except HTTPError as he:
        # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ–ª–æ –æ—à–∏–±–∫–∏
        try:
            err_body = he.read().decode("utf-8")
        except Exception:
            err_body = str(he)
        logger.error(f"Bot API HTTPError: {he.code} {err_body}")
        # –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π ‚Äî –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –±–µ–∑ parse_mode –∏ —Å plain-—Ç–µ–∫—Å—Ç–æ–º
        if he.code == 400 and "can't parse entities" in err_body.lower():
            try:
                plain = _md_to_plain(markdown_text)
                body2 = {
                    "chat_id": settings.TARGET_CHANNEL_ID,
                    "text": plain,
                    "disable_web_page_preview": settings.TELEGRAM_DISABLE_WEB_PREVIEW,
                }
                req2 = urlrequest.Request(
                    api_url,
                    data=json.dumps(body2, ensure_ascii=False).encode("utf-8"),
                    headers={"Content-Type": "application/json"},
                )
                with urlrequest.urlopen(req2, timeout=settings.TELEGRAM_TIMEOUT_SEC) as resp2:
                    raw2 = resp2.read().decode("utf-8", errors="ignore")
                    try:
                        j2 = json.loads(raw2)
                    except Exception:
                        j2 = None
                    ok2 = bool(j2 and j2.get("ok", False))
                    if not ok2:
                        logger.warning(f"Retry Bot API ok=false: {raw2[:200]}")
                    return ok2
            except Exception as e2:
                logger.exception(f"Retry without parse_mode failed: {e2}")
        # –ò–Ω–∞—á–µ ‚Äî –æ–±—ã—á–Ω—ã–π —Ñ–æ–ª–±—ç–∫
    except URLError as ue:
        logger.error(f"Bot API URLError: {ue}")
    except Exception as e:
        logger.exception(f"Bot API request failed: {e}")
    return False


@app.get("/health")
def health():
    return JSONResponse({
        "ok": True,
        "status": "ok",
        "service": "aggregator",
        "approved_dir": settings.APPROVED_DIR,
        "output_dir": settings.OUTPUT_DIR,
    })


@app.post("/api/aggregator/run")
def run_aggregation(limit: Optional[int] = None):
    items = _read_approved(limit or settings.BATCH_LIMIT)
    if not items:
        return JSONResponse({"ok": True, "result": "empty", "summary": ""})

    logger.info(f"Run aggregation: items={len(items)}")
    prompt = _compose_prompt(items, settings.SUMMARY_LANGUAGE)
    summary = _use_gemini(prompt)
    if not summary:
        logger.error("Gemini returned empty summary; aborting aggregation")
        return JSONResponse({"ok": False, "result": "gemini_failed", "error": "empty_summary"})

    # –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
    summary = _postprocess_summary(summary)

    out_name = settings.OUTPUT_SUMMARY_FILENAME
    out_path = os.path.join(settings.OUTPUT_DIR, out_name)
    wrote_ok = _write_summary_file(out_path, summary, encoding=settings.SUMMARY_FILE_ENCODING_RUN)

    removed: List[str] = []
    if wrote_ok:
        removed = _remove_approved(items)
    else:
        logger.warning("Summary not written; approved are kept")

    return JSONResponse({"ok": True, "result": "ok", "output": out_path, "removed": removed})


@app.post("/api/aggregator/publish_now")
def publish_now(limit: Optional[int] = None):
    items = _read_approved(limit or settings.BATCH_LIMIT)
    if not items:
        return JSONResponse({"ok": True, "result": "empty", "published": False})

    logger.info(f"Publish now: items={len(items)}")
    prompt = _compose_prompt(items, settings.SUMMARY_LANGUAGE)
    summary = _use_gemini(prompt)
    if not summary:
        logger.error("Gemini returned empty summary; aborting publish")
        return JSONResponse({"ok": False, "result": "gemini_failed", "published": False, "error": "empty_summary"})

    # –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
    summary = _postprocess_summary(summary)

    out_path = os.path.join(settings.OUTPUT_DIR, settings.OUTPUT_SUMMARY_FILENAME)
    wrote_ok = _write_summary_file(out_path, summary, encoding=settings.SUMMARY_FILE_ENCODING_PUBLISH)

    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
    text_to_send = summary
    if settings.TELEGRAM_PARSE_MODE and settings.TELEGRAM_PARSE_MODE.upper() == "HTML":
        text_to_send = _markdown_to_html_safe(summary)
    published = _publish_telegram(text_to_send)

    removed: List[str] = []
    if published:
        removed = _remove_approved(items)

    return JSONResponse({"ok": True, "result": "ok", "published": published, "output": out_path, "removed": removed})


def _build_message_url(payload: Dict[str, Any]) -> str:
    username = payload.get("channel_username")
    msg_id = payload.get("message_id")
    chan_id = payload.get("channel_id")
    try:
        if username and msg_id:
            return f"https://t.me/{username}/{msg_id}"
        if chan_id and msg_id:
            # –î–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø/–∫–∞–Ω–∞–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º t.me/c/<short_id>/<msg_id>
            cid = int(chan_id)
            if cid < 0:
                cid = -cid
            # short id –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ 100...
            short_id = cid - 1000000000000 if str(cid).startswith("100") else cid
            return f"https://t.me/c/{short_id}/{msg_id}"
    except Exception:
        pass
    return ""

_emoji_re = re.compile(r"^([\U0001F1E6-\U0001F1FF\U0001F300-\U0001FAFF\u2600-\u27FF])(?:\s*[\U0001F1E6-\U0001F1FF\U0001F300-\U0001FAFF\u2600-\u27FF]+)*\s*(.*)$")
_username_paren_re = re.compile(r"\s*\(@[A-Za-z0-9_]+\)")

def _postprocess_summary(text: str) -> str:
    lines = text.splitlines()
    out: List[str] = []
    first_in_block = True
    for ln in lines:
        if not ln.strip():
            out.append(ln)
            first_in_block = True
            continue
        cur = ln
        if first_in_block:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ ‚Äî –µ—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç, –æ–±–µ—Ä–Ω—ë–º –≤ ** ** –µ—Å–ª–∏ –Ω–µ –æ–±—ë—Ä–Ω—É—Ç
            if cur.startswith("**") and cur.endswith("**"):
                pass
            else:
                cur = f"**{cur}**"
            first_in_block = False
        else:
            # –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞: –æ–¥–∏–Ω —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ
            m = _emoji_re.match(cur)
            if m:
                cur = f"{m.group(1)} {m.group(2)}".strip()
            # –£–±—Ä–∞—Ç—å (@username) –≤ —Å–∫–æ–±–∫–∞—Ö
            cur = _username_paren_re.sub("", cur)
        out.append(cur)
    return "\n".join(out)

    removed: List[str] = []
    if wrote_ok:
        removed = _remove_approved(items)
    else:
        logger.warning("Summary not written; approved are kept")

    return JSONResponse({"ok": True, "result": "ok", "output": out_path, "removed": removed})